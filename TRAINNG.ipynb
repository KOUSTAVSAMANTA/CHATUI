{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJIpgL3xy5eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67626a60-e716-46f4-9592-893808079f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# %tensorflow_version 1.x\n",
        "# !pip install gpt-2-simple\n",
        "# !pip install -q transformers\n",
        "# !pip install tensorflow==1.15.0\n",
        "# import gpt_2_simple as gpt2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56GAKlfBKujn"
      },
      "source": [
        "# ***sent similarity***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqm5gS5sK0O_",
        "outputId": "4a0bc963-a9ff-40f1-9126-78360dc3381c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import torch#pytorch\n",
        "from transformers import AutoTokenizer, AutoModel#for embeddings\n",
        "from sklearn.metrics.pairwise import cosine_similarity#for similarity\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "#download pretrained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\",)\n",
        "model = AutoModel.from_pretrained(\"bert-large-uncased\",output_hidden_states=True,)\n",
        "\n",
        "#create embeddings\n",
        "def get_embeddings(text,token_length):\n",
        "  tokens=tokenizer(text,max_length=token_length,padding='max_length',truncation=True)\n",
        "  output=model(torch.tensor(tokens.input_ids).unsqueeze(0),\n",
        "               attention_mask=torch.tensor(tokens.attention_mask).unsqueeze(0)).hidden_states[-1]\n",
        "  return torch.mean(output,axis=1).detach().numpy()\n",
        "\n",
        "#calculate similarity\n",
        "\n",
        "\n",
        "def get_embeddings_list(text=[],length=20):\n",
        "  embd=[]\n",
        "  for i,j in tqdm(enumerate(text),total=len(text)):\n",
        "      out2=get_embeddings(j,token_length=length)\n",
        "      embd.append(out2)\n",
        "  return embd\n",
        "\n",
        "def calculate_similarity(embd_list=[],text3=\"\",token_length=20,text=[]):\n",
        "    out1=get_embeddings(text3,token_length=token_length)\n",
        "    # ind=[]\n",
        "    sim=[]\n",
        "    for j in embd_list:\n",
        "      sim1= cosine_similarity(out1,j)[0][0]\n",
        "      sim.append(sim1)\n",
        "      # ind.append(j)\n",
        "    print(sim)\n",
        "    element_matched=np.argmax(sim)\n",
        "    if sim[element_matched]!=0:\n",
        "      return text[element_matched]\n",
        "    else:\n",
        "      return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAf09DCzNPg4",
        "outputId": "0bced733-a37e-4eac-9077-ae80c3422b3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.argmax([0,0,0,0,0,0,])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzLemJc6MnAV",
        "outputId": "493f5370-4968-4419-d107-8c2f63261e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:13<00:00,  2.79it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "text1=['hello','bye','good morning','good evening','glove vector','halaluia of the day','ilove you','lets have a party today','we can meet tommorow','see you again','whatsapp','lets play a game','game of throns','ello','by','god morning','goo evening','glov vector','halluia of the day','iove you','letshave a party today','wecan meet tommorow','see you again','whatsapp','lets play a game','game of throns','hello2','1bye','good mrnng','good eening','gove vctor','halaluia of he day','iloe you','lets have a party tday','wecan meet tmmorow','see yu again','whatspp','lets play a gme','game of thron']\n",
        "\n",
        "embd= get_embeddings_list(text=text1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j=0\n",
        "while j<5:\n",
        "  i=input(\"\")\n",
        "  j=j+1\n",
        "  print(calculate_similarity(embd_list=embd,text3=i,token_length=20,text=text1))\n",
        "# len(embd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "0YzDQN1bDWBb",
        "outputId": "c396d439-c336-48e2-f42c-30602a8fae89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hola\n",
            "[0.71860504, 0.5939621, 0.64837563, 0.70647687, 0.7203603, 0.5889494, 0.76060295, 0.6837915, 0.60990715, 0.62714344, 0.6742264, 0.6074712, 0.6129353, 0.83359957, 0.7156468, 0.6731787, 0.73355603, 0.79985154, 0.6896479, 0.740275, 0.6517806, 0.70043725, 0.62714344, 0.6742264, 0.6074712, 0.6129353, 0.6513469, 0.63910604, 0.7260786, 0.7194643, 0.692269, 0.6358588, 0.8239362, 0.7387294, 0.6537291, 0.7330694, 0.65561235, 0.6656227, 0.6375578]\n",
            "ello\n",
            "how are you\n",
            "[0.7120342, 0.6077481, 0.8164164, 0.8006221, 0.5897421, 0.53546196, 0.69455254, 0.6924807, 0.6455456, 0.7601512, 0.6681035, 0.6698303, 0.5622207, 0.66251713, 0.63798904, 0.6672879, 0.5532856, 0.61244506, 0.58462614, 0.68438447, 0.5945667, 0.7014569, 0.7601512, 0.6681035, 0.6698303, 0.5622207, 0.71773434, 0.5911776, 0.7185623, 0.62746483, 0.58661175, 0.51294804, 0.6819831, 0.7117186, 0.62130225, 0.7313934, 0.69902307, 0.59858376, 0.6023408]\n",
            "good morning\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \"\"\"\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-801c68671a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membd_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdm-Q8GWOyAB"
      },
      "source": [
        "# ***REQUIREMENTS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBAB4EsiO18O",
        "outputId": "081bd0bf-7c8c-40f6-8a33-045bf4f8fa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi==0.68.1\n",
            "  Downloading fastapi-0.68.1-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting starlette==0.14.2\n",
            "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.68.1) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.68.1) (4.1.1)\n",
            "Installing collected packages: starlette, fastapi\n",
            "Successfully installed fastapi-0.68.1 starlette-0.14.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 53.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 62.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 64.9 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 71.6 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 68.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.8.1 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
            "\u001b[K     |████████████████████████████████| 745 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=96d4f4817eefb5b3a6c2a00f96378e7b61064366405380e52c3a02b846aae272\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting uvicorn==0.15.0\n",
            "  Downloading uvicorn-0.15.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[?25hCollecting asgiref>=3.4.0\n",
            "  Downloading asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (4.1.1)\n",
            "Installing collected packages: h11, asgiref, uvicorn\n",
            "Successfully installed asgiref-3.5.2 h11-0.13.0 uvicorn-0.15.0\n",
            "\u001b[K     |████████████████████████████████| 572 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 56.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 585 kB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 419 kB 66.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 56.6 MB/s \n",
            "\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 183 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.0)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30535 sha256=6adece81bc368a170a99ccb3c35f10e2c5bb7002baaa67ad605e5d4a2503ad1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=b42cb5f62682979112bc161a8bf2be24eb19c28ba81a51da6e54c8dd6a761e46\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=d3bb99bf8e80ace604a61f6b4950ca5dcd3040790d32e1327aeb07feb4715aa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.5\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 6.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.0.0\n",
            "  Downloading tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3 MB 50 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.19.5)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.14.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.47.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.17.3)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 65.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.4.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.25.11)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.0.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=2e104abe1459df4f7b20f87fb25c7d98887239eaad09499166bf4bab2bb78dbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "pytorch-lightning 1.6.5 requires tensorboard>=2.2.0, but you have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Collecting dnspython<3.0.0,>=1.16.0\n",
            "  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n",
            "\u001b[K     |████████████████████████████████| 269 kB 7.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: dnspython\n",
            "Successfully installed dnspython-2.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi==0.68.1\n",
        "!pip install datasets\n",
        "!pip install nest-asyncio\n",
        "!pip install pyngrok\n",
        "!pip install uvicorn==0.15.0\n",
        "!pip install -q aitextgen\n",
        "!pip install bert-for-tf2\n",
        "!pip install numpy==1.19.5\n",
        "!pip install tensorflow==2.0.0\n",
        "!pip install h5py==2.10.0\n",
        "!pip install pymongo\n",
        "!pip install pymongo[srv]\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "078AdimpMTG9"
      },
      "source": [
        "# ***false code***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I4_s9yyo9rd",
        "outputId": "b0697e71-be6c-44f9-e2c2-e719cf5951ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vK9uhkrR6HoW",
        "outputId": "146a2c77-cd2f-4402-b0ac-4763182616f1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xBcNyfatzAB3",
        "outputId": "279b1a9e-3bf4-48e5-e09a-c2726f2fc57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.46.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 65.0 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.6)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=d5d77aa923213f50ae0b8aeb03a48da08491675200a9a0382539919a4a958eb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\n",
            "gpt-2-simple 0.8.1 requires tensorflow>=2.5.1, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Wq3HuqzQYY",
        "outputId": "708bb9e2-d10e-4224-ef58-dcb554a9d68a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 252Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 589kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 644Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [03:23, 6.97Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 551Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 659kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 745kit/s]\n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")\n",
        "# import tensorflow as tf\n",
        "# tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ROGqj2EzSB5"
      },
      "outputs": [],
      "source": [
        "file_name = \"/content/datasql.txt\" #data directory\n",
        "# d=[]\n",
        "# with open(file_name,'r') as f:\n",
        "#   for line in f:\n",
        "#     d.append(line)\n",
        "\n",
        "# z=d[:200]\n",
        "# with open(\"/content/drive/MyDrive/gpt-data/chatbot5.txt\",'w') as f:\n",
        "#   for line in z:\n",
        "#         try:\n",
        "#             f.write(line)\n",
        "#         except:\n",
        "#             pass  \n",
        "\n",
        "\n",
        "\n",
        "sess = gpt2.start_tf_sess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "eXHMkAyS0htb",
        "outputId": "80eb34e1-7b8c-4b2a-9344-6731b35ecf03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You need to download the GPT-2 model first via download_gpt2()\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-508bab1ae357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0maccumulate_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/model/gptmodel/checkpoint\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m               \u001b[0msave_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m               \u001b[0;31m# reuse=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m               )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfnf_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You need to download the GPT-2 model first via download_gpt2()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnf_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             shutil.copyfile(os.path.join(model_dir, model_name, file),\n\u001b[0;32m--> 172\u001b[0;31m                             os.path.join(checkpoint_path, file))\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfnf_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You need to download the GPT-2 model first via download_gpt2()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/355M/hparams.json'"
          ]
        }
      ],
      "source": [
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='SQLBOT',\n",
        "              print_every=10,\n",
        "              sample_every=100,\n",
        "              use_memory_saving_gradients = True,\n",
        "\t            only_train_transformer_layers = True,\n",
        "\t            accumulate_gradients = 1,\n",
        "              checkpoint_dir=\"/content/drive/MyDrive/model/gptmodel/checkpoint\",\n",
        "              save_every=100,\n",
        "              # reuse=True\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnHNlmhrFE4I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRZeIoyU0zm3"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xNteh70k7b9d",
        "outputId": "1d277d8c-d3fa-47ff-d5f8-7b51ebdde015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ]
        },
        {
          "ename": "NotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key beta1_power not found in checkpoint\n\t [[{{node save_2/RestoreV2}}]]\n\t [[save_2/RestoreV2/_4689]]\n  (1) Not found: Key beta1_power not found in checkpoint\n\t [[{{node save_2/RestoreV2}}]]\n0 successful operations.\n0 derived errors ignored.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1290\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: 2 root error(s) found.\n  (0) Not found: Key beta1_power not found in checkpoint\n\t [[node save_2/RestoreV2 (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[save_2/RestoreV2/_4689]]\n  (1) Not found: Key beta1_power not found in checkpoint\n\t [[node save_2/RestoreV2 (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_2/RestoreV2':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-b13c8cc9d6b6>\", line 2, in <module>\n    gpt2.load_gpt2(sess,run_name='runINSURANCE',checkpoint_dir=\"/content/drive/MyDrive/model/gptmodel/checkpoint\",model_name=\"355M\",reuse=True)\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\", line 401, in load_gpt2\n    saver = tf.compat.v1.train.Saver(allow_empty=True)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1299\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m   \u001b[0mobject_graph_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader_GetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b13c8cc9d6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'runINSURANCE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/model/gptmodel/checkpoint\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"355M\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Question : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mload_gpt2\u001b[0;34m(sess, checkpoint, run_name, checkpoint_dir, model_name, model_dir, multi_gpu, reuse)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading checkpoint'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1306\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\n2 root error(s) found.\n  (0) Not found: Key beta1_power not found in checkpoint\n\t [[node save_2/RestoreV2 (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\t [[save_2/RestoreV2/_4689]]\n  (1) Not found: Key beta1_power not found in checkpoint\n\t [[node save_2/RestoreV2 (defined at /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'save_2/RestoreV2':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-b13c8cc9d6b6>\", line 2, in <module>\n    gpt2.load_gpt2(sess,run_name='runINSURANCE',checkpoint_dir=\"/content/drive/MyDrive/model/gptmodel/checkpoint\",model_name=\"355M\",reuse=True)\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\", line 401, in load_gpt2\n    saver = tf.compat.v1.train.Saver(allow_empty=True)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 828, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 840, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 878, in _build\n    build_restore=build_restore)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 508, in _build_internal\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 328, in _AddRestoreOps\n    restore_sequentially)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py\", line 575, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\", line 1696, in restore_v2\n    name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
          ]
        }
      ],
      "source": [
        "z = 0\n",
        "gpt2.load_gpt2(sess,run_name='runINSURANCE',checkpoint_dir=\"/content/drive/MyDrive/model/gptmodel/checkpoint\",model_name=\"355M\",reuse=True)\n",
        "while z < 25:\n",
        "    ques = input(\"Question : \")\n",
        "    z = z + 1\n",
        "\n",
        "    inp = '[YOU] : ' + ques + '\\n' + '[BOT] :'\n",
        "    # inp=ques\n",
        "    x = gpt2.generate(sess,\n",
        "                      length=15,\n",
        "                      temperature=0.7,\n",
        "                      include_prefix=False,\n",
        "                      prefix=inp,\n",
        "                      nsamples=1,\n",
        "                      run_name='runINSURANCE',\n",
        "                      checkpoint_dir=\"/content/drive/MyDrive/model/gptmodel/checkpoint\",\n",
        "                      model_name='355M',\n",
        "                      return_as_list=True)[0]\n",
        "    ans = x.split(\"\\n\")\n",
        "    # ans = x.split(\"\\n\")\n",
        "    print(ans[1])\n",
        "    # print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqjYiHsNDetk",
        "outputId": "5aaa2fa6-e72b-4153-8b9e-3ec0bee8f6ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 362 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 70.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install -q aitextgen\n",
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *training using aitextgen*"
      ],
      "metadata": {
        "id": "-ohOf9uppC95"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yYTomPyzpCd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHaZ5iJ-pI_G"
      },
      "outputs": [],
      "source": [
        "from aitextgen import aitextgen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekyyif02pPMp"
      },
      "outputs": [],
      "source": [
        "ai = aitextgen(tf_gpt2=\"355M\", to_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlhzn1mHpR_m"
      },
      "outputs": [],
      "source": [
        "ai.train('/content/drive/MyDrive/gpt-data/chatbot.txt',\n",
        "         line_by_line=False,\n",
        "         from_cache=False,\n",
        "         output_dir=\"/content/drive/MyDrive/model/gptmodel/trained_model2\",\n",
        "         num_steps=500,\n",
        "         generate_every=100,\n",
        "         save_every=500,\n",
        "         save_gdrive=False,\n",
        "         learning_rate=1e-4,\n",
        "         fp16=False,\n",
        "         batch_size=1, \n",
        "         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwF7WyUCqI44",
        "outputId": "e1cab9de-ebdf-4d5a-b4d4-7e0e0ca8ebea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ],
      "source": [
        "ai = aitextgen(model_folder=\"/content/drive/MyDrive/model/gptmodel/trained_model2/\", config=\"/content/drive/MyDrive/model/gptmodel/trained_model2/config.json\", to_gpu=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWMz5a2HrO72"
      },
      "outputs": [],
      "source": [
        "ai.generate(n=3,\n",
        "            prompt='[YOU] : nice to meet you \\n[BOT] :',\n",
        "            batch_size=1,\n",
        "            max_length=50,\n",
        "            temperature=0.1,\n",
        "            top_p=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***IF have tensorflow model convert to pytorcg***"
      ],
      "metadata": {
        "id": "1gbdip-wpLlf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsbHB7DPrmr-",
        "outputId": "0042d6fd-588e-480b-9324-63775c95e364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting TensorFlow checkpoint from /content/drive/MyDrive/model/gptmodel/checkpoint/runINSURANCE+chitchat\n",
            "Loading TF weight model/h0/attn/c_attn/b with shape [3072]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/transformers-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/commands/transformers_cli.py\", line 55, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/commands/convert.py\", line 151, in run\n",
            "    convert_gpt2_checkpoint_to_pytorch(self._tf_checkpoint, self._config, self._pytorch_dump_output)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py\", line 38, in convert_gpt2_checkpoint_to_pytorch\n",
            "    load_tf_weights_in_gpt2(model, config, gpt2_checkpoint_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 93, in load_tf_weights_in_gpt2\n",
            "    array = tf.train.load_variable(tf_path, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/checkpoint_utils.py\", line 84, in load_variable\n",
            "    return reader.get_tensor(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 915, in get_tensor\n",
            "    return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str))\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/drive/MyDrive/model/gptmodel/checkpoint/runINSURANCE+chitchat/model-1000.data-00000-of-00001; No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!transformers-cli convert --model_type gpt2 --tf_checkpoint /content/drive/MyDrive/model/gptmodel/checkpoint/runINSURANCE+chitchat --pytorch_dump_output /content/drive/MyDrive/model/gptmodel/pytorchchitins/ --config /content/drive/MyDrive/model/gptmodel/checkpoint/runINSURANCE+chitchat/hparams.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS5-wDzWzIDh",
        "outputId": "062c43e5-7431-449b-ff1a-e863ce3b7a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi==0.68.1\n",
            "  Downloading fastapi-0.68.1-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 811 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi==0.68.1) (1.8.2)\n",
            "Collecting starlette==0.14.2\n",
            "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
            "\u001b[K     |████████████████████████████████| 60 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.68.1) (4.1.1)\n",
            "Installing collected packages: starlette, fastapi\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.19.1\n",
            "    Uninstalling starlette-0.19.1:\n",
            "      Successfully uninstalled starlette-0.19.1\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.78.0\n",
            "    Uninstalling fastapi-0.78.0:\n",
            "      Successfully uninstalled fastapi-0.78.0\n",
            "Successfully installed fastapi-0.68.1 starlette-0.14.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting uvicorn==0.15.0\n",
            "  Downloading uvicorn-0.15.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (4.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.15.0) (7.1.2)\n",
            "Collecting asgiref>=3.4.0\n",
            "  Downloading asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: h11, asgiref, uvicorn\n",
            "Successfully installed asgiref-3.5.2 h11-0.13.0 uvicorn-0.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi==0.68.1\n",
        "# !pip install datasets\n",
        "!pip install nest-asyncio\n",
        "!pip install pyngrok\n",
        "!pip install uvicorn==0.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo2pcww4bSa-"
      },
      "source": [
        "# ***CHAT GENERATOR***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDYCVlkgzIfa"
      },
      "outputs": [],
      "source": [
        "# !pip install -q aitextgen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "5lY5ylRbzIw_",
        "outputId": "8776a8c1-48b5-4ffd-8408-56434f410ce7"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-652f995d3ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maitextgen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maitextgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maitextgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/model/gptmodel/pytorch3/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/model/gptmodel/pytorch3/config.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generating\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/aitextgen/aitextgen.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, model_folder, config, vocab_file, merges_file, tokenizer_file, schema_tokens, schema_return, cache_dir, tf_gpt2, to_gpu, to_fp16, verbose, gradient_checkpointing, bos_token, eos_token, unk_token, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m             assert os.path.exists(\n\u001b[1;32m    171\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pytorch_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             ), f\"There is no pytorch_model.bin in /{model_folder}.\"\n\u001b[0m\u001b[1;32m    173\u001b[0m             assert os.path.exists(\n\u001b[1;32m    174\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: There is no pytorch_model.bin in //content/drive/MyDrive/model/gptmodel/pytorch3/."
          ]
        }
      ],
      "source": [
        "from aitextgen import aitextgen\n",
        "ai = aitextgen(model_folder=\"/content/drive/MyDrive/model/gptmodel/pytorch3/\", config=\"/content/drive/MyDrive/model/gptmodel/pytorch3/config.json\", to_gpu=True)\n",
        "\n",
        "print(\"generating\")\n",
        "def gener(text):\n",
        "    z = ai.generate(n=3,\n",
        "                prompt='[YOU] : '+text+' \\n[BOT] :',\n",
        "                batch_size=1,\n",
        "                # max_length=50,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                return_as_list=True)[0]\n",
        "    ans = z.split(\"\\n\")\n",
        "    pre=ans[1].split(\"[BOT] : \")\n",
        "    return pre[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3_L-YENsaJh"
      },
      "outputs": [],
      "source": [
        "# kl=0\n",
        "# while kl<3:\n",
        "#   kl=kl+1\n",
        "#   i=input(\" \")\n",
        "#   print(gener(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p__5yLrAdoM"
      },
      "source": [
        "## ***APIHOSTING***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw5cnegvvQ8o"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "# from main import gener\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "origins = ['*']\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=origins,\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "\n",
        "class Course(BaseModel):\n",
        "    msg: str\n",
        "    sent: str\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"Hello World\"}\n",
        "\n",
        "\n",
        "@app.post(\"/postdata\")\n",
        "def create_course(course: Course):\n",
        "    x=gener(course.msg)\n",
        "    intk=intent(course.msg)\n",
        "    entk=entities(course.msg)\n",
        "    dbk = datapush(qus=course.msg,intk=intk,entk=entk,ans=x,sent=course.sent)\n",
        "    return x\n",
        "\n",
        "# uvicorn sample:app --reload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjUJWhQ_Em7B"
      },
      "outputs": [],
      "source": [
        "# !pip install fastapi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4qOuiS0AVFg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeSbFMRa0CwY",
        "outputId": "34ba6015-fe1e-4b40-d103-b3cc474de845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auth_token = \"2BtQpP3t1CKXckhb3e9udhsXRb9_5mHtGSwwYUa2xiaqHwCrc\"\n",
        "import os\n",
        "os.system(f\"ngrok authtoken {auth_token}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIdns82e0Liv"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8000, port='8000', bind_tls=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ses4QD9V0ORO",
        "outputId": "e64d8486-71d9-4a75-b11a-f5edef020e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root         794 12.5  0.1 726908 24132 ?        Sl   13:03   0:00 /usr/local/lib/python3.7/dist-packages/pyngrok/bin/ngrok start --none --log=stdout\n",
            "root         806  0.0  0.0  39200  6592 ?        S    13:03   0:00 /bin/bash -c ps aux | grep ngrok\n",
            "root         808  0.0  0.0  38572  4960 ?        S    13:03   0:00 grep ngrok\n"
          ]
        }
      ],
      "source": [
        "!ps aux | grep ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uXC13PB0jZR",
        "outputId": "0caeb3ef-d41b-43fd-81ef-ca9944c42664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NgrokTunnel: \"https://dc69-34-143-177-34.ngrok.io\" -> \"http://localhost:8000\"\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "# Allow for asyncio to work within the Jupyter notebook cell https://ce93-35-247-159-187.ngrok.io\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import uvicorn\n",
        "\n",
        "# Run the FastAPI app using uvicorn\n",
        "print(public_url)\n",
        "uvicorn.run(app)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhDkCWbf0oHt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwztcxitOuOt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3ju1bMm2Uyh"
      },
      "source": [
        "# **DATA PREPARATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQH-qydQ2cfy"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOCDfbh2c_m",
        "outputId": "c73841ff-be91-4bf6-d1d1-820bccfdf90c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<csv.DictReader object at 0x7fc714ae3c90>\n"
          ]
        }
      ],
      "source": [
        "dict = {}\n",
        "dat={}\n",
        "with open('/content/customer_training.csv', newline='') as csvfile:\n",
        "  reader = csv.DictReader(csvfile)\n",
        "  print(reader)\n",
        "  d=[]\n",
        "  d2=[]\n",
        "  inte=[]\n",
        "  for row in reader:\n",
        "    # print(row['INTENT_NAME'],row['UTTERANCES'])\n",
        "    d.append([row['UTTERANCES'],row['INTENT_NAME']])\n",
        "    dat[row['INTENT_NAME']] =  row['UTTERANCES']\n",
        "    if row['INTENT_NAME'] not in inte:\n",
        "      inte.append(row['INTENT_NAME'])\n",
        "    else:\n",
        "      pass\n",
        "# print(dat.keys())\n",
        "dict['train'] = d\n",
        "# print(dict) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eeXolfuCVzY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# print(dict)\n",
        "json_object = json.dumps(dict, indent = 4)\n",
        "\n",
        "with open(\"d2test1.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S6E3UTjmBEs",
        "outputId": "d297640d-c8c7-4a28-82f4-8a8530f2764a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<csv.DictReader object at 0x7fc71476e650>\n"
          ]
        }
      ],
      "source": [
        "with open('/content/customer_testing.csv', newline='') as csvfile:\n",
        "  reader = csv.DictReader(csvfile)\n",
        "  print(reader)\n",
        "  di=[]\n",
        "  # d2=[]\n",
        "  # inte=[]\n",
        "  for row in reader:\n",
        "    # print(row['INTENT_NAME'],row['UTTERANCES'])\n",
        "    di.append([row['UTTERANCES'],row['INTENT_NAME']])\n",
        "    dat[row['INTENT_NAME']] =  row['UTTERANCES']\n",
        "    if row['INTENT_NAME'] not in inte:\n",
        "      inte.append(row['INTENT_NAME'])\n",
        "    else:\n",
        "      pass\n",
        "# print(dat.keys())\n",
        "dict['test'] = di"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp8TTokVDOkn",
        "outputId": "5e341c25-de2d-448a-a2ab-4ec76fdaacee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO_ADD_HOUSE 34\n",
            "INFO_ADD_REMOVE_INSURED 47\n",
            "INFO_ADD_REMOVE_VEHICLE 57\n",
            "INFO_ADD_VEHICLE_PROPERTY_PAPERLESS_BILLING 21\n",
            "INFO_AGENT_WRONG 22\n",
            "INFO_AGT_NOT_RESPONDING 33\n",
            "INFO_AMERICAN_STAR 53\n",
            "INFO_AMT_DUE 24\n",
            "INFO_AST_PURCHASE 65\n",
            "INFO_AST_QUOTE 88\n",
            "INFO_ATV_INS_EXPLAN 17\n",
            "INFO_AUTO_COV_QUESTION 44\n",
            "INFO_AUTO_INS_CANADA 59\n",
            "INFO_AUTO_POLICY_CANT_SEE_IN_ACCT 60\n",
            "INFO_AUTO_PYMT_CANCEL 51\n",
            "INFO_AUTO_PYMT_MIN_BALANCE 136\n",
            "INFO_AUTO_PYMT_SCHEDULE 36\n",
            "INFO_BILL_DUE_DATE 69\n",
            "INFO_BILLING_ACCT_NAME_EDIT 25\n",
            "INFO_BILLING_ACCT_NUM 40\n",
            "INFO_BILLING_DEPT_CONTACT 54\n",
            "INFO_BOAT_COV_EXPLAN 46\n",
            "INFO_BUSINESS_POLICY_CANT_SEE 77\n",
            "INFO_CANCEL_CONFIRM 50\n",
            "INFO_CANCEL_FEE 33\n",
            "INFO_CANCEL_INS_POLICY 26\n",
            "INFO_CANT_SEE_FARM_RANCH_POLICY 23\n",
            "INFO_CANT_SEE_POLICY 72\n",
            "INFO_CAREERS 36\n",
            "INFO_CFR_QUESTION_GENERAL 40\n",
            "INFO_CHANGE_AGENT 25\n",
            "INFO_CHANGE_AUTOPAY_DATE 66\n",
            "INFO_CHANGE_BANK_ACCT 40\n",
            "INFO_CHANGE_USERID 20\n",
            "INFO_CL_ADJUSTER_INFO 50\n",
            "INFO_CL_CHECK_STATUS 124\n",
            "INFO_CL_CLAIM_FILED 49\n",
            "INFO_CL_COMPLAINT 58\n",
            "INFO_CL_DOCS_EMAIL 43\n",
            "INFO_CL_DOCS_FAX 82\n",
            "INFO_CL_DOCS_MAIL 69\n",
            "INFO_CL_DOCS_SEND 48\n",
            "INFO_CL_DRP_ASSIGN 114\n",
            "INFO_CL_DRP_JOIN 33\n",
            "INFO_CL_FILE_CLAIM 62\n",
            "INFO_CL_FNOL 47\n",
            "INFO_CL_FNOL_AUTO_HAIL 20\n",
            "INFO_CL_GLASS_SAFELITE 81\n",
            "INFO_CL_RENTAL 65\n",
            "INFO_CL_SHOP_ADD_WORK 89\n",
            "INFO_CL_SHOP_SEND_ESTIMATE 86\n",
            "INFO_CL_STATUS 88\n",
            "INFO_CL_UPDATE_INFO 84\n",
            "INFO_COLL_COV_EXPLAN 41\n",
            "INFO_COLLECTIONS 38\n",
            "INFO_COMBINE_PYMTS 53\n",
            "INFO_COMP_COV_EXPLAN 38\n",
            "INFO_CONFIRM_COVERAGE 86\n",
            "INFO_CREDIT_CARD_CHANGE_NUM 38\n",
            "INFO_CREDIT_CARD_FEE 42\n",
            "INFO_CUSTOMER_SERVICE_HOURS 17\n",
            "INFO_DEC_PAGE_NEEDED 36\n",
            "INFO_DED_EXPLAN 30\n",
            "INFO_DEDUCTIBLE 57\n",
            "INFO_DELETE_DUPE_PYMT 66\n",
            "INFO_DIFFERENT_AMTS 63\n",
            "INFO_DISCOUNTS 35\n",
            "INFO_DO_NOT_CONTACT 18\n",
            "INFO_DREAMKEEP_REWARDS 26\n",
            "INFO_DREAMKEEP_REWARDS_ERRORS 188\n",
            "INFO_DREAMS_FOUNDATION 53\n",
            "INFO_EMPLOYMENT_VERIFY 38\n",
            "INFO_ERS 13\n",
            "INFO_ERS_CONTACT 50\n",
            "INFO_FIND_AGENT 13\n",
            "INFO_FLOOD_INS_EXPLAN 53\n",
            "INFO_FORGOT_EMAIL 31\n",
            "INFO_FORGOT_PASSWORD 36\n",
            "INFO_FORGOT_USERID 19\n",
            "INFO_GAP_COVERAGE 26\n",
            "INFO_GEN_POLICY_COV_QUESTION 41\n",
            "INFO_GET_A_QUOTE_AUTO 40\n",
            "INFO_GET_A_QUOTE_AUTO_NONOWNER 46\n",
            "INFO_GET_A_QUOTE_CFR 48\n",
            "INFO_GET_A_QUOTE_OTHER 39\n",
            "INFO_GET_A_QUOTE_RENTERS 45\n",
            "INFO_GET_A_QUOTE_RENTERS_PURCHASE 31\n",
            "INFO_GLASS_COV 45\n",
            "INFO_HANDLING_FEE_REMOVE 54\n",
            "INFO_HEALTH_INS_QUOTE 46\n",
            "INFO_HOMESITE_CONTACT 29\n",
            "INFO_INS_CARD_PROOF 37\n",
            "INFO_INS_CARD_PRINT 18\n",
            "INFO_INS_CARD_SEND 65\n",
            "INFO_INS_NOT_AVAILABLE 63\n",
            "INFO_KNOWYOURDRIVE 172\n",
            "INFO_KNOWYOURDRIVE_DEVICE_ACTIVATE 31\n",
            "INFO_KNOWYOURDRIVE_DEVICE_RETURN 62\n",
            "INFO_KNOWYOURDRIVE_ERRORS 30\n",
            "INFO_LETTER_OF_EXPERIENCE 44\n",
            "INFO_LIAB_EXPLAN 80\n",
            "INFO_LIFE_BENEFICIARY_CHANGE 35\n",
            "INFO_LIFE_CASH_OUT 36\n",
            "INFO_LIFE_INCR_COV 36\n",
            "INFO_LIFE_POLICY_AMT_DUE 34\n",
            "INFO_LIFE_POLICY_AUTO_PYMT 38\n",
            "INFO_LIFE_POLICY_CANCEL 40\n",
            "INFO_LIFE_POLICY_CANNOT_SEE 70\n",
            "INFO_LIFE_QUESTION_GENERAL 36\n",
            "INFO_LIFE_REFUND 52\n",
            "INFO_LIFE_UPDATE_CONTACT_INFO 69\n",
            "INFO_LOG_OUT 32\n",
            "INFO_LOGIN_ERROR 62\n",
            "INFO_MAIL_PYMT_ADDRESS 47\n",
            "INFO_MAKE_PYMT 24\n",
            "INFO_MEXICO_AUTO_INS 86\n",
            "INFO_MORTGAGE_CO_POI 142\n",
            "INFO_NAME_CHANGE 32\n",
            "INFO_NEW_VEHICLE_GRACE_PERIOD 143\n",
            "INFO_ONE_TIME_PYMT 48\n",
            "INFO_OPERATING_AREA 60\n",
            "INFO_OPERATING_CO 41\n",
            "INFO_PAPERLESS_DOCS_SETUP 24\n",
            "INFO_PAPERLESS_DOCS_STOP 67\n",
            "INFO_PAPERLESS_MAIL 84\n",
            "INFO_PAY_LIFE_INS 36\n",
            "INFO_PHONE_NUM 34\n",
            "INFO_PHONE_NUM_INTERNATIONAL 47\n",
            "INFO_POI_OLD 152\n",
            "INFO_POLICY_DOC_NEEDED 44\n",
            "INFO_POLICY_NUM 32\n",
            "INFO_POLICY_TRANS_TO_RENTAL 60\n",
            "INFO_PREMIUM_BREAKDOWN 58\n",
            "INFO_PREPAID_CARD_PYMT 54\n",
            "INFO_PYMT_CONFIRM 34\n",
            "INFO_PYMT_DUEDATE_CHANGE 38\n",
            "INFO_PYMT_ERROR 36\n",
            "INFO_PYMT_HISTORY 44\n",
            "INFO_PYMT_NOT_ONTIME 33\n",
            "INFO_PYMT_PROCESS_CHANGE 41\n",
            "INFO_PYMT_SETUP_AUTO_PYMT 35\n",
            "INFO_PYMT_TIME 59\n",
            "INFO_REFUND_CHECK 37\n",
            "INFO_REINSTATE_INS_POLICY 53\n",
            "INFO_RENTERS_COV_EXPLAN 28\n",
            "INFO_RIDESHARE_COV 63\n",
            "INFO_RV_INS_EXPLAN 20\n",
            "INFO_SALVAGE_VEHICLE 134\n",
            "INFO_SET_UP_ACCT 22\n",
            "INFO_SPEAK_TO_REP 34\n",
            "INFO_srtwentytwo 80\n",
            "INFO_TEEN_SAFE_DRIVER_SIGNUP 36\n",
            "INFO_THE_GENERAL_CONTACT 26\n",
            "INFO_TRANSFER_ACCT_BALANCE 44\n",
            "INFO_TRAVEL_INS_EXPLAN 29\n",
            "INFO_UPDATE_CONTACT_INFO 38\n",
            "INFO_UPDATE_EMAIL 24\n",
            "INFO_UPDATE_LIENHOLDER 50\n",
            "INFO_UPDATE_PHONE_NUM 62\n",
            "INFO_UW_ALUMNI_DISCOUNT 39\n",
            "INFO_WHO_IS_MY_AGENT 87\n",
            "INFO_WHY_WAS_POLICY_CANCELLED 48\n",
            "NO 14\n",
            "ST_GENERAL_REQUEST 15\n",
            "ST_HELLO 7\n",
            "ST_HOW_IS_ABBY 8\n",
            "ST_HOW_OLD_IS_ABBY 18\n",
            "ST_IS_ABBY_REAL 21\n",
            "ST_THANK_YOU 49\n",
            "ST_WHAT_CAN_ABBY_DO 29\n",
            "ST_WHERE_DOES_ABBY_LIVE 23\n",
            "YES 9\n",
            "INFO_CL_HRP_JOIN 64\n",
            "INFO_ERS_REIMBURSE 24\n",
            "INFO_PROFILE_SECTION 45\n"
          ]
        }
      ],
      "source": [
        "len(inte)\n",
        "z=[]\n",
        "for i in inte:\n",
        " print(i,len(dat[i]))\n",
        "#  z.append(len(dat[i]))\n",
        "# kl=[]\n",
        "# for i in inte:\n",
        "\n",
        "  # kl.append([dat[i],i])\n",
        "# print(kl)\n",
        "# dict['test'] = kl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga4gfXeTGcLV"
      },
      "source": [
        "# ***INTENT RECOGNITION***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5JVhm9SGhYd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import bert\n",
        "from bert import BertModelLayer\n",
        "from bert.loader import StockBertConfig, map_stock_config_to_params, load_stock_weights\n",
        "from bert.tokenization.bert_tokenization import FullTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG8FrM4RHB2Q",
        "outputId": "b523e5b0-e29c-4526-e8cd-8c37eb72b968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bert-for-tf2 in /usr/local/lib/python3.7/dist-packages (0.14.9)\n",
            "Requirement already satisfied: params-flow>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.8.2)\n",
            "Requirement already satisfied: py-params>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from bert-for-tf2) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install bert-for-tf2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uredm7oGHFGN"
      },
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWolvVl3HFUq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('d2test1.json') as json_file:\n",
        "    CLINC150 = json.load(json_file)\n",
        "CLINC150_train=CLINC150['train']\n",
        "CLINC150_test=CLINC150['test']\n",
        "# CLINC150_val=CLINC150['val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7iwxG-mHnBQ",
        "outputId": "8b5fd716-9119-45f1-dc28-a8a61e15439f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['new_id_card', 'claim_status', 'file_a_claim', 'make_payment', 'get_a_quote']\n",
            "98\n"
          ]
        }
      ],
      "source": [
        "# classes=inte[:10]\n",
        "classes=z\n",
        "print(classes)\n",
        "print(len(l2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJh9j560Yhdl"
      },
      "outputs": [],
      "source": [
        "train_data,test_data= train_test_split(l2,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv7Ow8hpHpvj",
        "outputId": "81671024-9ff3-4bf7-901b-5d89b4b19b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['view my recent claims', 'claim_status'], [\"what's my bill\", 'make_payment'], ['file a claim', 'file_a_claim'], ['check the status of a claim', 'claim_status'], ['check the status of claim [NC339723](claim_id)[NC339723](claim_id)', 'claim_status'], ['i need a new insurance card', 'new_id_card'], ['i want to check the status of my claim', 'claim_status'], ['get a new id card', 'new_id_card'], ['i need an insurance quote', 'get_a_quote'], ['payment', 'make_payment'], ['i need to file a claim', 'file_a_claim'], ['pay bill', 'make_payment'], ['submit a payment', 'make_payment'], ['what is the status of my claim?', 'claim_status'], ['what is the status of claim [XX123456](claim_id)[XX123456](claim_id)', 'claim_status'], ['what is my claim history', 'claim_status'], ['order a new id card', 'new_id_card'], ['i need a quote', 'get_a_quote'], ['order new id card', 'new_id_card'], ['pay off a [claim](payment_type)', 'make_payment'], [\"i'm looking to purchase insurance\", 'get_a_quote'], ['show my claims', 'claim_status'], ['check claim status', 'claim_status'], ['how much will insurance cost?', 'get_a_quote'], ['my insurance card is lost', 'new_id_card'], ['check status of my claim', 'claim_status'], ['pay [claim](payment_type)', 'make_payment'], ['show some claims', 'claim_status'], ['claim status', 'claim_status'], ['make a [claim](payment_type) payment', 'make_payment'], ['get claim status', 'claim_status'], ['send me a new id card', 'new_id_card'], ['file a [health](quote_insurance_type) insurance claim', 'file_a_claim'], ['I need to check my claim status', 'claim_status'], ['has my claim been paid?', 'claim_status'], ['i need [health](quote_insurance_type) insurance', 'get_a_quote'], ['check the status of claim [ZZ643421](claim_id)', 'claim_status'], ['i crashed my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}', 'file_a_claim'], [\"i can't find my ID card\", 'new_id_card'], ['has claim [YY4567890](claim_id) been paid?', 'claim_status'], ['new id card', 'new_id_card'], ['has my claim been processed?', 'claim_status'], ['has my claim been submitted?', 'claim_status'], ['can you send me a new id card?', 'new_id_card'], ['do i owe a payment', 'make_payment'], [\"i can't find my id card\", 'new_id_card'], ['i need insurance', 'get_a_quote'], ['check claim id 748536', 'claim_status'], ['insurance quote', 'get_a_quote'], ['file [health](quote_insurance_type) insurance claim', 'file_a_claim'], ['i need to insure my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}', 'get_a_quote'], ['file new claim', 'file_a_claim'], ['what is the status of my recent claim?', 'claim_status'], ['submit a claim', 'file_a_claim'], ['pay what i owe', 'make_payment'], ['check on my claim status', 'claim_status'], ['pay my bill', 'make_payment'], ['i was in a [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} crash', 'file_a_claim'], ['get new insurance', 'get_a_quote'], ['pay my deductible', 'make_payment'], ['what is the status of claim [XX123456](claim_id)', 'claim_status'], ['file a [life](quote_insurance_type) insurance claim', 'file_a_claim'], ['make a claim', 'file_a_claim'], ['quote', 'get_a_quote'], ['a tree fell on my [house](quote_insurance_type)', 'file_a_claim'], ['show me my claims', 'claim_status'], ['i need [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} insurance', 'get_a_quote'], ['i had a procedure and need to file a claim', 'file_a_claim'], ['pay a [claim](payment_type)', 'make_payment'], ['give me a [health](quote_insurance_type) insurance quote', 'get_a_quote'], ['check the status of claim [NC239062](claim_id)', 'claim_status'], ['view my claims', 'claim_status'], ['how do i get a new id card?', 'new_id_card'], ['make a new claim', 'file_a_claim'], ['what do i owe on my claim?', 'claim_status'], ['i need a new id card', 'new_id_card'], ['what is the status of claim [X123456](claim_id)', 'claim_status'], ['how much will coverage cost?', 'get_a_quote'], ['can i get an insurance quote?', 'get_a_quote'], ['bill', 'make_payment'], ['can you give me a quote?', 'get_a_quote'], ['how much will [healthcare](quote_insurance_type) insurance cost?', 'get_a_quote'], ['was my claim paid?', 'claim_status'], ['actually file a claim', 'file_a_claim'], ['i want to pay a [claim](payment_type)', 'make_payment'], ['i lost id card', 'new_id_card'], ['get a quote', 'get_a_quote'], ['submit a new claim', 'file_a_claim']]\n"
          ]
        }
      ],
      "source": [
        "# train_data=[]\n",
        "print(train_data)\n",
        "# test_data=[]\n",
        "# # val_data=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24w9Ao-uHsLO"
      },
      "outputs": [],
      "source": [
        "for c in CLINC150_train:\n",
        "    if c[1] in classes:\n",
        "        train_data.append(c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzWk5Ar3HuTb"
      },
      "outputs": [],
      "source": [
        "# for c in CLINC150_test:\n",
        "#     if c[1] in classes:\n",
        "#         test_data.append(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgf8XcSOHvia"
      },
      "outputs": [],
      "source": [
        "# for c in CLINC150_val:\n",
        "#     if c[1] in classes:\n",
        "#         val_data.append(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ee0_B8gqHw0S",
        "outputId": "88fd70c4-bd78-4d6c-9f91-77f648bd05de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text        intent\n",
              "0                              view my recent claims  claim_status\n",
              "1                                     what's my bill  make_payment\n",
              "2                                       file a claim  file_a_claim\n",
              "3                        check the status of a claim  claim_status\n",
              "4  check the status of claim [NC339723](claim_id)...  claim_status"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0deafdb-e7a2-4937-b61f-0d12c18480de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>view my recent claims</td>\n",
              "      <td>claim_status</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what's my bill</td>\n",
              "      <td>make_payment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>file a claim</td>\n",
              "      <td>file_a_claim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>check the status of a claim</td>\n",
              "      <td>claim_status</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>check the status of claim [NC339723](claim_id)...</td>\n",
              "      <td>claim_status</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0deafdb-e7a2-4937-b61f-0d12c18480de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0deafdb-e7a2-4937-b61f-0d12c18480de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0deafdb-e7a2-4937-b61f-0d12c18480de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df = pd.DataFrame(train_data)\n",
        "df.to_csv('train_data.csv', index=False,header=('text','intent'))\n",
        "train=pd.read_csv('train_data.csv')\n",
        "print(len(train))\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLcy18DmHyPN"
      },
      "outputs": [],
      "source": [
        "# df = pd.DataFrame(val_data)\n",
        "# df.to_csv('val_data.csv', index=False,header=('text','intent'))\n",
        "# valid=pd.read_csv('val_data.csv')\n",
        "# print(len(valid))\n",
        "# valid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "smC76baZH1FH",
        "outputId": "142b831c-8670-4369-ec3c-a257b634eed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text        intent\n",
              "0                                   file a new claim  file_a_claim\n",
              "1                                check up on a claim  claim_status\n",
              "2  i'm in the market to get [life](quote_insuranc...   get_a_quote\n",
              "3                             tell me about my claim  claim_status\n",
              "4  i need a quote for [car](quote_insurance_type)...   get_a_quote"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a67d202-cb29-46f0-a988-e673a124eee4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>file a new claim</td>\n",
              "      <td>file_a_claim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>check up on a claim</td>\n",
              "      <td>claim_status</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm in the market to get [life](quote_insuranc...</td>\n",
              "      <td>get_a_quote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me about my claim</td>\n",
              "      <td>claim_status</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i need a quote for [car](quote_insurance_type)...</td>\n",
              "      <td>get_a_quote</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a67d202-cb29-46f0-a988-e673a124eee4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a67d202-cb29-46f0-a988-e673a124eee4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a67d202-cb29-46f0-a988-e673a124eee4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df = pd.DataFrame(test_data)\n",
        "df.to_csv('test_data.csv', index=False,header=('text','intent'))\n",
        "test=pd.read_csv('test_data.csv')\n",
        "print(len(test))\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq2I_jvwH2uc"
      },
      "outputs": [],
      "source": [
        "train = train.append(valid).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfuCWLGPH4No"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"model\", exist_ok=True)\n",
        "bert_model_name=\"uncased_L-12_H-768_A-12\"\n",
        "bert_ckpt_dir = os.path.join(\"/content/drive/MyDrive/model/\", bert_model_name)\n",
        "bert_ckpt_file = os.path.join(bert_ckpt_dir, \"bert_model.ckpt\")\n",
        "bert_config_file = os.path.join(bert_ckpt_dir, \"bert_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL8TaKYZH55J"
      },
      "outputs": [],
      "source": [
        "# !wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enpzlVs4IK5q"
      },
      "outputs": [],
      "source": [
        "# !unzip -o uncased_L-12_H-768_A-12.zip -d \"/content/drive/MyDrive/model/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSSnzkLaIbGk"
      },
      "outputs": [],
      "source": [
        "class DataPreparation:\n",
        "    \n",
        "    text_column = \"text\"\n",
        "    label_column = \"intent\"\n",
        "\n",
        "    def __init__(self, train, test, tokenizer: FullTokenizer, classes, max_seq_len=192):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_len = 0\n",
        "        self.classes = classes\n",
        "\n",
        "        ((self.train_x, self.train_y), (self.test_x, self.test_y)) = map(self.prepare_data, [train, test])\n",
        "\n",
        "        print(\"max seq_len\", self.max_seq_len)\n",
        "        self.max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "        self.train_x, self.test_x = map(self.data_padding, [self.train_x, self.test_x])\n",
        "\n",
        "    def prepare_data(self, df):\n",
        "        x, y = [], []\n",
        "\n",
        "        for _, row in tqdm(df.iterrows()):\n",
        "            text, label = row[DataPreparation.text_column], row[DataPreparation.label_column]\n",
        "            tokens = self.tokenizer.tokenize(text)\n",
        "            tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "            token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "            self.max_seq_len = max(self.max_seq_len, len(token_ids))\n",
        "            x.append(token_ids)\n",
        "            y.append(self.classes.index(label))\n",
        "\n",
        "        return np.array(x), np.array(y)\n",
        "\n",
        "    def data_padding(self, ids):\n",
        "        x = []\n",
        "        for input_ids in ids:\n",
        "            input_ids = input_ids[:min(len(input_ids), self.max_seq_len - 2)]\n",
        "            input_ids = input_ids + [0] * (self.max_seq_len - len(input_ids))\n",
        "            x.append(np.array(input_ids))\n",
        "        return np.array(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUAx0IGgIoAB"
      },
      "outputs": [],
      "source": [
        "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_ckpt_dir, \"vocab.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U00WDmJIqWH"
      },
      "outputs": [],
      "source": [
        "def model_defination(max_seq_len, bert_ckpt_file):\n",
        "    \n",
        "    with tf.io.gfile.GFile(bert_config_file, \"r\") as reader:\n",
        "        bc = StockBertConfig.from_json_string(reader.read())\n",
        "        bert_params = map_stock_config_to_params(bc)\n",
        "        bert_params.adapter_size = None\n",
        "        bert = BertModelLayer.from_params(bert_params, name=\"bert\")\n",
        "        \n",
        "    input_ids = keras.layers.Input(shape=(max_seq_len, ), dtype='int32', name=\"input_ids\")\n",
        "    bert_output = bert(input_ids)\n",
        "\n",
        "    print(\"bert shape\", bert_output.shape)\n",
        "\n",
        "    cls_out = keras.layers.Lambda(lambda seq: seq[:, 0, :])(bert_output)\n",
        "    cls_out = keras.layers.Dropout(0.5)(cls_out)\n",
        "    logits = keras.layers.Dense(units=768, activation=\"tanh\")(cls_out)\n",
        "    logits = keras.layers.Dropout(0.5)(logits)\n",
        "    # logits = keras.layers.Dense(units=768, activation=\"tanh\")(logits)\n",
        "    # logits = keras.layers.Dropout(0.5)(logits)\n",
        "    logits = keras.layers.Dense(units=len(classes), activation=\"softmax\")(logits)\n",
        "\n",
        "    model = keras.Model(inputs=input_ids, outputs=logits)\n",
        "    model.build(input_shape=(None, max_seq_len))\n",
        "\n",
        "    load_stock_weights(bert, bert_ckpt_file)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YeJU2TCCURG"
      },
      "outputs": [],
      "source": [
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL4BksEmIvT4"
      },
      "outputs": [],
      "source": [
        "# classes = train.intent.unique().tolist()\n",
        "\n",
        "import joblib\n",
        "\n",
        "# filename=\"classes2.sav\"\n",
        "# joblib.dump(classes, filename)\n",
        "\n",
        "filename=\"classes2.sav\"\n",
        "classes=joblib.load( filename)\n",
        "\n",
        "# data = DataPreparation(train, test, tokenizer, classes, max_seq_len=128)\n",
        "\n",
        "# filename=\"data2.sav\"\n",
        "# joblib.dump(data, filename)\n",
        "\n",
        "filename=\"data2.sav\"\n",
        "data=joblib.load(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuiYBXd-IxpZ",
        "outputId": "8c5e89e2-6863-41da-f2e8-d790b77721fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "data.train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrhXx2vqI0qL",
        "outputId": "ac37442e-e679-4a7f-91f8-e474b2e1a74c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 101, 3193, 2026, 3522, 4447,  102,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data.train_x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJMvaCr-I2h7",
        "outputId": "2495e0ee-2fde-4353-eda1-3cd05d154395"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data.train_y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGcS3PpxI30z",
        "outputId": "0a7ac578-a89d-4a3f-907e-6f98a650a17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert shape (None, 33, 768)\n",
            "Done loading 196 BERT weights from: /content/drive/MyDrive/model/uncased_L-12_H-768_A-12/bert_model.ckpt into <bert.model.BertModelLayer object at 0x7fe3f1a0c3d0> (prefix:bert). Count of weights not found in the checkpoint was: [0]. Count of weights with mismatched shape: [0]\n",
            "Unused weights from checkpoint: \n",
            "\tbert/embeddings/token_type_embeddings\n",
            "\tbert/pooler/dense/bias\n",
            "\tbert/pooler/dense/kernel\n",
            "\tcls/predictions/output_bias\n",
            "\tcls/predictions/transform/LayerNorm/beta\n",
            "\tcls/predictions/transform/LayerNorm/gamma\n",
            "\tcls/predictions/transform/dense/bias\n",
            "\tcls/predictions/transform/dense/kernel\n",
            "\tcls/seq_relationship/output_bias\n",
            "\tcls/seq_relationship/output_weights\n"
          ]
        }
      ],
      "source": [
        "model = model_defination(data.max_seq_len, bert_ckpt_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yGXYkYTI6Bq"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy==1.19.5\n",
        "# !pip install tensorflow==2.0.0\n",
        "print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZJux6KPJXHJ",
        "outputId": "0a560efb-a393-44cb-ac61-0f9d9dc42f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, 33)]              0         \n",
            "_________________________________________________________________\n",
            "bert (BertModelLayer)        (None, 33, 768)           108890112 \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 768)               590592    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 3845      \n",
            "=================================================================\n",
            "Total params: 109,484,549\n",
            "Trainable params: 109,484,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laC8MK4IKqqv"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer=keras.optimizers.Adam(1e-5),\n",
        "  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Training code***"
      ],
      "metadata": {
        "id": "k7SP3rOwp8p7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjbSGZSQp5ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng1CRGoEKsqK",
        "outputId": "24df3806-d95e-4b55-863c-7801d107e23f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 79 samples, validate on 9 samples\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 52s 664ms/sample - loss: 1.6011 - acc: 0.2405 - val_loss: 1.6480 - val_acc: 0.1111\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 30s 379ms/sample - loss: 1.5560 - acc: 0.3544 - val_loss: 1.6794 - val_acc: 0.1111\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 29s 371ms/sample - loss: 1.5292 - acc: 0.3797 - val_loss: 1.7016 - val_acc: 0.1111\n",
            "Epoch 4/10\n",
            "32/79 [===========>..................] - ETA: 15s - loss: 1.3732 - acc: 0.5625"
          ]
        }
      ],
      "source": [
        "log_dir = \"/content/drive/MyDrive/model/log/intent_detection4/\" + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[-3]\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "history = model.fit(\n",
        "  x=data.train_x, \n",
        "  y=data.train_y,\n",
        "  validation_split=0.1,\n",
        "  batch_size=16,\n",
        "  shuffle=True,\n",
        "  epochs=10,\n",
        "  callbacks=[tensorboard_callback]\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY7VBezQYX0z"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/model/intentent-5.hdf5')\n",
        "# model.load_weights(\"/content/drive/MyDrive/model/intentent.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f1fuYXiCxv7"
      },
      "outputs": [],
      "source": [
        "  # !pip install h5py==2.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-kUrPi2bhsd"
      },
      "source": [
        "# ***loading model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AGFUIgTeY5H_",
        "outputId": "41a188f7-33b4-44e2-cc06-9b92ad996aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "88/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 14s 154ms/sample - loss: 1.3070 - acc: 0.6477\n",
            "10/1 [============================================================================================================================================================================================================================================================================================================] - 1s 108ms/sample - loss: 1.2786 - acc: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# _, train_acc = model.evaluate(data.train_x, data.train_y)\n",
        "# _, test_acc = model.evaluate(data.test_x, data.test_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rgLI5Z1Ja0GA",
        "outputId": "2c904356-a176-4e7b-8371-51932011bc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train acc 0.64772725\n",
            "test acc 0.7\n"
          ]
        }
      ],
      "source": [
        "# print(\"train acc\", train_acc)\n",
        "\n",
        "# print(\"test acc\", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8am8KvLY7uz"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model.load_weights('/content/drive/MyDrive/model/intentent-5-2.hdf5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3cbBFQxas8s"
      },
      "outputs": [],
      "source": [
        "# !pip install 'h5py==2.10.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SJjVSWKK4OV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def intent(txt):\n",
        "  sentences = [txt]\n",
        "  pred_tokens = map(tokenizer.tokenize, sentences)\n",
        "  pred_tokens = map(lambda tok: [\"[CLS]\"] + tok + [\"[SEP]\"], pred_tokens)\n",
        "  pred_token_ids = list(map(tokenizer.convert_tokens_to_ids, pred_tokens))\n",
        "  pred_token_ids = map(\n",
        "    lambda tids: tids +[0]*(data.max_seq_len-len(tids)),\n",
        "    pred_token_ids\n",
        "  )\n",
        "  pred_token_ids = np.array(list(pred_token_ids))\n",
        "  predictions = model.predict(pred_token_ids).argmax(axis=-1)\n",
        "  for text, label in zip(sentences, predictions):\n",
        "      return classes[label]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0hJEVjyln_C",
        "outputId": "e25f57e4-cf66-40f5-e5e2-cf4f01cc4f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make_payment\n"
          ]
        }
      ],
      "source": [
        "print(intent(\"pay this bill\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0CqeqpclpN8"
      },
      "source": [
        "# ***Entity Extraction***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAOsXy9Nlwrc"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Q_0O4Mo_UU",
        "outputId": "fb511533-458c-4dea-cf54-bb56386b69a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 400.7 MB 6.0 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.3.0) (3.3.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.6.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.19.5)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.11.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.7.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.4.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5IqmK18nxL0"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    str1 = \" \" \n",
        "    \n",
        "    # return string  \n",
        "    return (str1.join(s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWOO-Zc_n5CD"
      },
      "outputs": [],
      "source": [
        "def entities(txt):\n",
        "  doc = nlp(txt)\n",
        "  text = [ent.text for ent in doc.ents]\n",
        "  # entity = [ent.label_ for ent in doc.ents]\n",
        "  return listToString(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhAzHOX3oJ1b",
        "outputId": "adc7ff47-cf7e-4522-b463-d1888cd88acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ['INFO_ADD_REMOVE_INSURED']\n"
          ]
        }
      ],
      "source": [
        "print(entities(\"I want to remove someone from my car policy as they will not be driving my vehicle anymore\"),[intent(\"I want to remove someone from my car policy as they will not be driving my vehicle anymore\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giZOJdaFoMl5"
      },
      "outputs": [],
      "source": [
        "# entity\n",
        "# from collections import Counter\n",
        "# import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDcC8BsZoRZi"
      },
      "outputs": [],
      "source": [
        "# data = Counter(zip(entity))\n",
        "# unique_entity = list(data.keys())        \n",
        "# unique_entity = [x[0] for x in unique_entity]        \n",
        "# d = {}        \n",
        "# for val in unique_entity:\n",
        "#   d[val] = []\n",
        "# for key,val in dict(zip(text, entity)).items():\n",
        "#   if val in unique_entity:\n",
        "#     d[val].append(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoCI4PdgouWo"
      },
      "outputs": [],
      "source": [
        "# d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D1VEcp3o16J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y7LrZzs7GVC"
      },
      "source": [
        "# ***DATABASE CONNECTION***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjma3Jrx7KtL",
        "outputId": "ae828cdc-9099-4a59-acb5-d922610a4de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pymongo[srv]) (2.2.1)\n"
          ]
        }
      ],
      "source": [
        "# mongodb+srv://koustav:<password>@cluster0.9onpa.mongodb.net/?retryWrites=true&w=majority\n",
        "!pip install pymongo\n",
        "!pip install pymongo[srv]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J1nzzhR7Tci"
      },
      "outputs": [],
      "source": [
        "import pymongo\n",
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BmDpxcH7eGd"
      },
      "outputs": [],
      "source": [
        "cluster = MongoClient(\"mongodb+srv://koustav:koustav2003@cluster0.9onpa.mongodb.net/?retryWrites=true&w=majority\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrRif9A677Xy"
      },
      "outputs": [],
      "source": [
        "db = cluster[\"DATA\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YUl1CiR8Ana"
      },
      "outputs": [],
      "source": [
        "collection = db[\"normaldata\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcNw1Dplc0Eq"
      },
      "outputs": [],
      "source": [
        "def datapush(qus,intk,entk,ans,sent):\n",
        "  collection.insert_one({\"question\":qus,\n",
        "                        \"intent\":intk,\n",
        "                        \"entity\":entk,\n",
        "                        \"sentiment\":sent,\n",
        "                        \"answer\":ans})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jkt59tJk8g8D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnYnquSU9LvR"
      },
      "outputs": [],
      "source": [
        "collection1 = db[\"NLU\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KivaLmu8-QKp"
      },
      "outputs": [],
      "source": [
        "# q=[]\n",
        "# a=[]\n",
        "# with open('chatbot.txt','r') as f:\n",
        "#   for line in f:\n",
        "#     if '[YOU]' in line:\n",
        "#       l=line.split(':')\n",
        "#       _l=l[1].strip(\"\\n\")\n",
        "#       q.append(_l)\n",
        "#     elif '[BOT]' in line:\n",
        "#       l=line.split(':')\n",
        "#       _l=l[1].strip(\"\\n\")\n",
        "#       a.append(_l)\n",
        "\n",
        "# print(len(q),len(a))\n",
        "  \n",
        "# z=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swiAmWpiBhp3"
      },
      "outputs": [],
      "source": [
        "# for i in range(len(q)):\n",
        "#   d={\"question\":q[i],\"answer\":a[i]}\n",
        "#   z.append(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I3siPLrB74b"
      },
      "outputs": [],
      "source": [
        "# print(len(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ClGdASdB7-Q"
      },
      "outputs": [],
      "source": [
        "# collection.insert_many(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTdxw2-5C9AQ"
      },
      "outputs": [],
      "source": [
        "question=[]\n",
        "for x in collection1.find():\n",
        "  question.append(x['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVMChThjDQGq"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def findans(ques):\n",
        "  print(ques)\n",
        "  ans=[]\n",
        "  for x in collection1.find({'question':ques}):\n",
        "    ans.append(x['answer'])\n",
        "    print(ans)\n",
        "  finalanswer=random.choice(ans)\n",
        "  return finalanswer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "QS3k0ZQiUnZh",
        "outputId": "8a6498ea-7498-4e09-912c-4baa1de94c3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what are your interests\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d102cb1a65da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfindans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'what are your interests'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-32df21cb42e9>\u001b[0m in \u001b[0;36mfindans\u001b[0;34m(ques)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mfinalanswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfinalanswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36mchoice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
          ]
        }
      ],
      "source": [
        "findans('what are your interests')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "5MoZw21LGFo0",
        "outputId": "e0226f51-8996-4230-b5fd-57ee02d91f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "what is your favorite number\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c17815dcfbb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfindans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-9253e66a6bc0>\u001b[0m in \u001b[0;36mcalculate_similarity\u001b[0;34m(text, text3, token_length)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# ind=[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mout2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0msim1\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-9253e66a6bc0>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(text, token_length)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   output=model(torch.tensor(tokens.input_ids).unsqueeze(0),\n\u001b[0;32m---> 13\u001b[0;31m                attention_mask=torch.tensor(tokens.attention_mask).unsqueeze(0)).hidden_states[-1]\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m         )\n\u001b[1;32m   1030\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                 )\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         )\n\u001b[1;32m    538\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "j=0\n",
        "while j<5:\n",
        "  i=input(\"\")\n",
        "  j=j+1\n",
        "  z = calculate_similarity(text=question[:100],text3=i,token_length=len(i))\n",
        "  print(type(z))\n",
        "  print(findans(z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUctwjYQGEIc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO8q8XG8GEL1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_40XglDIOV6"
      },
      "source": [
        "# ***DATACREATION***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbgbB0qaeyeB"
      },
      "outputs": [],
      "source": [
        "!pip install deeppavlov==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm600_kMdMkW"
      },
      "outputs": [],
      "source": [
        "from deeppavlov.dataset_readers.insurance_reader import InsuranceReader \n",
        "\n",
        "# from deeppavlov.dataset_readers.dstc2_reader import SimpleDSTC2DatasetReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDdRISKVdm1w"
      },
      "outputs": [],
      "source": [
        "data = InsuranceReader().read('/content/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmNoqmG3g8CK"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/shuzi/insuranceQA.git\n",
        "\n",
        "# !ls my_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHpQ0CUOhEBN"
      },
      "outputs": [],
      "source": [
        "# print(data.items())\n",
        "from itertools import islice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS2Dr2cKhKSw",
        "outputId": "628788b1-1206-49d6-fc1f-11c24f95d614"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=0\n",
        "len(data)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQlayP9ZkVlK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab7biMZRlw-h"
      },
      "outputs": [],
      "source": [
        "z=data['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o4hs2JznAHF"
      },
      "outputs": [],
      "source": [
        "with open(\"chatbot.txt\",'a') as f:\n",
        "  for i in z:\n",
        "    # print(i[1])\n",
        "    f.writelines(\"[YOU] : \"+i[0][0]+'\\n')\n",
        "    f.writelines(\"[BOT] : \"+i[0][1]+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wuVcjiunxJu",
        "outputId": "7eb36388-de53-4bf2-e901-eec9440b64c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53790\n"
          ]
        }
      ],
      "source": [
        "k=[]\n",
        "with open(\"chatbot.txt\",'r') as f:\n",
        "  for i in f:\n",
        "    k.append(i)\n",
        "print(len(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPJz-Pv4eepu",
        "outputId": "b36b6619-d519-4ee2-b0a2-f6faea776061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9224\n"
          ]
        }
      ],
      "source": [
        "k=[]\n",
        "with open(\"extradata.txt\",'r') as f:\n",
        "  for i in f:\n",
        "    k.append(i)\n",
        "print(len(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oJXa1WwEpIJ"
      },
      "outputs": [],
      "source": [
        "with open(\"chatbot.txt\",'a') as f:\n",
        "  for i in k:\n",
        "    # print(i[1])\n",
        "    f.writelines(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QPk-vB5LEu9E",
        "outputId": "e3906486-634f-4309-e8c9-9db8b05e8c48"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[BOT] : what do you get when you cross a road and a strawberry\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k[1003]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NhRw6AU4EyCY",
        "outputId": "6ea6b8fc-7cb0-4fa8-faaf-0f135c2da66e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[YOU] : you do n't have the money\\n\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k[9000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "046-5qTnEz9f",
        "outputId": "427dd2ae-3582-4acb-e60c-3b63ab75be23"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[YOU] : i think i 'm going to explode\\n\""
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k[50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "wQftpccyE3Ow",
        "outputId": "cfd96256-bf68-4e6d-f162-ff257b9f04af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[BOT] : life insurance pay thebeneficiaryof the policy Thebeneficiarycan use the death benefitproceeds in any way they deem fit if debt be cumbersome to the family or business the proceeds can be use pay debt down or eliminate it all together the large debt be generally a home mortgage Manybeneficiariesretire theirmortgage from lifeinsuranceproceeds\\n'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k[90000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "X8HDdoo4E7U6",
        "outputId": "38c36144-14d8-4ea6-fe42-d99595b756fb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[YOU] : be Life Insurance exempt from creditor in Connecticut\\n'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBeIi6fhE-ZH",
        "outputId": "3d7a9c2a-bafd-4b08-b6a2-fbd89879c6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "['intent: new_id_card\\n', '- i lost my id card\\n', '- how do i get a new id card?\\n', '- i need a new id card\\n', '- new id card\\n', '- i need a new insurance card\\n', '- my insurance card is lost\\n', \"- i can't find my id card\\n\", '    - send me a new id card\\n', '    - can you send me a new id card?\\n', '    - order a new id card\\n', '    - I need a new ID card\\n', '    - order new id card\\n', '    - get a new id card\\n', \"    - i can't find my ID card\\n\", '    - i lost id card\\n', 'intent: claim_status\\n', '    - what is the status of my claim?\\n', '    - claim status\\n', '    - has my claim been processed?\\n', '    - tell me about my claim\\n', '    - has my claim been paid?\\n', '    - was my claim paid?\\n', '    - what do i owe on my claim?\\n', '    - i want to check the status of my claim\\n', '    - what is the status of claim [X123456](claim_id)\\n', '    - has claim [YY4567890](claim_id) been paid?\\n', '    - check the status of claim [ZZ643421](claim_id)\\n', '    - check the status of a claim\\n', '    - I need to check my claim status\\n', '    - check claim status\\n', '    - view my claims\\n', '    - show my claims\\n', '    - view my recent claims\\n', '    - show me my claims\\n', '    - what is my claim history\\n', '    - get claim status\\n', '    - show some claims\\n', '    - check claim id 748536\\n', '    - check the status of claim [NC239062](claim_id)\\n', '    - has my claim been submitted?\\n', '    - what is the status of claim [XX123456](claim_id)[XX123456](claim_id)\\n', '    - check up on a claim\\n', '    - what is the status of claim [XX123456](claim_id)\\n', '    - what is the status of claim [NC709186](claim_id)[NC709186](claim_id)?\\n', '    - what is the status of my recent claim?\\n', '    - check the status of claim [NC339723](claim_id)[NC339723](claim_id)\\n', '    - check status of my claim\\n', '    - check on my claim status\\n', 'intent: file_a_claim\\n', '    - file a claim\\n', '    - make a claim\\n', '    - i need to file a claim\\n', '    - submit a claim\\n', '    - submit a new claim\\n', '    - make a new claim\\n', '    - i crashed my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}\\n', '    - file new claim\\n', '    - file a [health](quote_insurance_type) insurance claim\\n', '    - file [health](quote_insurance_type) insurance claim\\n', '    - a tree fell on my [house](quote_insurance_type)\\n', '    - file a [life](quote_insurance_type) insurance claim\\n', '    - i had a procedure and need to file a claim\\n', '    - actually file a claim\\n', '    - i was in a [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} crash\\n', '    - file a new claim\\n', 'intent: make_payment\\n', '    - pay a [claim](payment_type)\\n', '    - make a payment\\n', '    - pay off a [claim](payment_type)\\n', '    - pay what i owe\\n', '    - pay my bill\\n', '    - submit a payment\\n', '    - pay [claim](payment_type)\\n', '    - pay bill\\n', '    - i want to pay a [claim](payment_type)\\n', '    - make a [claim](payment_type) payment\\n', '    - payment\\n', '    - bill\\n', \"    - what's my bill\\n\", '    - do i owe a payment\\n', '    - pay my deductible\\n', 'intent: get_a_quote\\n', '    - i need insurance\\n', '    - i need [health](quote_insurance_type) insurance\\n', '    - i need a quote\\n', '    - i need a quote for [car](quote_insurance_type) insurance\\n', '    - how much will [healthcare](quote_insurance_type) insurance cost?\\n', '    - can you give me a quote for [life](quote_insurance_type) insurance?\\n', '    - quote\\n', '    - insurance quote\\n', '    - can you give me a quote?\\n', '    - how much will coverage cost?\\n', '    - how much will insurance cost?\\n', '    - can i get an insurance quote?\\n', '    - i need an insurance quote\\n', '    - give me a [health](quote_insurance_type) insurance quote\\n', '    - get a quote\\n', \"    - i'm looking to purchase insurance\\n\", \"    - i'm in the market to get [life](quote_insurance_type) insurance\\n\", '    - get new insurance\\n', '    - i need [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} insurance\\n', '    - i need to insure my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}']\n"
          ]
        }
      ],
      "source": [
        "z=[]\n",
        "l=[]\n",
        "with open('newint.txt','r') as f:\n",
        "  for i in f:\n",
        "    l.append(i)\n",
        "    # print(i.split(\" \"))\n",
        "    if 'intent:' in i.split(\" \"):\n",
        "      z.append(i.split(\": \")[1].strip(\"\\n\"))\n",
        "    \n",
        "    else:\n",
        "      pass\n",
        "\n",
        "clss5=len(z)\n",
        "print(len(z))\n",
        "print(l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Tq1V_D-NrL",
        "outputId": "def84608-3abe-4236-8874-4fb093777836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['new_id_card', 'intent: new_id_card\\n'], ['new_id_card', '- i lost my id card\\n'], ['new_id_card', '- how do i get a new id card?\\n'], ['new_id_card', '- i need a new id card\\n'], ['new_id_card', '- new id card\\n'], ['new_id_card', '- i need a new insurance card\\n'], ['new_id_card', '- my insurance card is lost\\n'], ['new_id_card', \"- i can't find my id card\\n\"], ['new_id_card', '    - send me a new id card\\n'], ['new_id_card', '    - can you send me a new id card?\\n'], ['new_id_card', '    - order a new id card\\n'], ['new_id_card', '    - I need a new ID card\\n'], ['new_id_card', '    - order new id card\\n'], ['new_id_card', '    - get a new id card\\n'], ['new_id_card', \"    - i can't find my ID card\\n\"], ['new_id_card', '    - i lost id card\\n'], ['claim_status', 'intent: claim_status\\n'], ['claim_status', '    - what is the status of my claim?\\n'], ['claim_status', '    - claim status\\n'], ['claim_status', '    - has my claim been processed?\\n'], ['claim_status', '    - tell me about my claim\\n'], ['claim_status', '    - has my claim been paid?\\n'], ['claim_status', '    - was my claim paid?\\n'], ['claim_status', '    - what do i owe on my claim?\\n'], ['claim_status', '    - i want to check the status of my claim\\n'], ['claim_status', '    - what is the status of claim [X123456](claim_id)\\n'], ['claim_status', '    - has claim [YY4567890](claim_id) been paid?\\n'], ['claim_status', '    - check the status of claim [ZZ643421](claim_id)\\n'], ['claim_status', '    - check the status of a claim\\n'], ['claim_status', '    - I need to check my claim status\\n'], ['claim_status', '    - check claim status\\n'], ['claim_status', '    - view my claims\\n'], ['claim_status', '    - show my claims\\n'], ['claim_status', '    - view my recent claims\\n'], ['claim_status', '    - show me my claims\\n'], ['claim_status', '    - what is my claim history\\n'], ['claim_status', '    - get claim status\\n'], ['claim_status', '    - show some claims\\n'], ['claim_status', '    - check claim id 748536\\n'], ['claim_status', '    - check the status of claim [NC239062](claim_id)\\n'], ['claim_status', '    - has my claim been submitted?\\n'], ['claim_status', '    - what is the status of claim [XX123456](claim_id)[XX123456](claim_id)\\n'], ['claim_status', '    - check up on a claim\\n'], ['claim_status', '    - what is the status of claim [XX123456](claim_id)\\n'], ['claim_status', '    - what is the status of claim [NC709186](claim_id)[NC709186](claim_id)?\\n'], ['claim_status', '    - what is the status of my recent claim?\\n'], ['claim_status', '    - check the status of claim [NC339723](claim_id)[NC339723](claim_id)\\n'], ['claim_status', '    - check status of my claim\\n'], ['claim_status', '    - check on my claim status\\n'], ['file_a_claim', 'intent: file_a_claim\\n'], ['file_a_claim', '    - file a claim\\n'], ['file_a_claim', '    - make a claim\\n'], ['file_a_claim', '    - i need to file a claim\\n'], ['file_a_claim', '    - submit a claim\\n'], ['file_a_claim', '    - submit a new claim\\n'], ['file_a_claim', '    - make a new claim\\n'], ['file_a_claim', '    - i crashed my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}\\n'], ['file_a_claim', '    - file new claim\\n'], ['file_a_claim', '    - file a [health](quote_insurance_type) insurance claim\\n'], ['file_a_claim', '    - file [health](quote_insurance_type) insurance claim\\n'], ['file_a_claim', '    - a tree fell on my [house](quote_insurance_type)\\n'], ['file_a_claim', '    - file a [life](quote_insurance_type) insurance claim\\n'], ['file_a_claim', '    - i had a procedure and need to file a claim\\n'], ['file_a_claim', '    - actually file a claim\\n'], ['file_a_claim', '    - i was in a [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} crash\\n'], ['file_a_claim', '    - file a new claim\\n'], ['make_payment', 'intent: make_payment\\n'], ['make_payment', '    - pay a [claim](payment_type)\\n'], ['make_payment', '    - make a payment\\n'], ['make_payment', '    - pay off a [claim](payment_type)\\n'], ['make_payment', '    - pay what i owe\\n'], ['make_payment', '    - pay my bill\\n'], ['make_payment', '    - submit a payment\\n'], ['make_payment', '    - pay [claim](payment_type)\\n'], ['make_payment', '    - pay bill\\n'], ['make_payment', '    - i want to pay a [claim](payment_type)\\n'], ['make_payment', '    - make a [claim](payment_type) payment\\n'], ['make_payment', '    - payment\\n'], ['make_payment', '    - bill\\n'], ['make_payment', \"    - what's my bill\\n\"], ['make_payment', '    - do i owe a payment\\n'], ['make_payment', '    - pay my deductible\\n'], ['get_a_quote', 'intent: get_a_quote\\n'], ['get_a_quote', '    - i need insurance\\n'], ['get_a_quote', '    - i need [health](quote_insurance_type) insurance\\n'], ['get_a_quote', '    - i need a quote\\n'], ['get_a_quote', '    - i need a quote for [car](quote_insurance_type) insurance\\n'], ['get_a_quote', '    - how much will [healthcare](quote_insurance_type) insurance cost?\\n'], ['get_a_quote', '    - can you give me a quote for [life](quote_insurance_type) insurance?\\n'], ['get_a_quote', '    - quote\\n'], ['get_a_quote', '    - insurance quote\\n'], ['get_a_quote', '    - can you give me a quote?\\n'], ['get_a_quote', '    - how much will coverage cost?\\n'], ['get_a_quote', '    - how much will insurance cost?\\n'], ['get_a_quote', '    - can i get an insurance quote?\\n'], ['get_a_quote', '    - i need an insurance quote\\n'], ['get_a_quote', '    - give me a [health](quote_insurance_type) insurance quote\\n'], ['get_a_quote', '    - get a quote\\n'], ['get_a_quote', \"    - i'm looking to purchase insurance\\n\"], ['get_a_quote', \"    - i'm in the market to get [life](quote_insurance_type) insurance\\n\"], ['get_a_quote', '    - get new insurance\\n'], ['get_a_quote', '    - i need [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} insurance\\n'], ['get_a_quote', '    - i need to insure my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}']]\n"
          ]
        }
      ],
      "source": [
        "k=[]\n",
        "intent =\"\"\n",
        "for i in l:\n",
        "  if 'intent' in i:\n",
        "    intent=i.split(\": \")[1].strip(\"\\n\")\n",
        "  k.append([intent,i])\n",
        "\n",
        "print(k)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcqft7HwB6Ks"
      },
      "outputs": [],
      "source": [
        "l2=[]\n",
        "for i in k:\n",
        "  if i[0] in i[1]:\n",
        "    pass\n",
        "  else:\n",
        "    l2.append([i[1].split(\"- \")[1].strip(\"\\n\"),i[0]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zF6_N7JVhwE",
        "outputId": "79212e29-bbb6-40e2-a07f-6224bbead88e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['i lost my id card', 'new_id_card'],\n",
              " ['how do i get a new id card?', 'new_id_card'],\n",
              " ['i need a new id card', 'new_id_card'],\n",
              " ['new id card', 'new_id_card'],\n",
              " ['i need a new insurance card', 'new_id_card'],\n",
              " ['my insurance card is lost', 'new_id_card'],\n",
              " [\"i can't find my id card\", 'new_id_card'],\n",
              " ['send me a new id card', 'new_id_card'],\n",
              " ['can you send me a new id card?', 'new_id_card'],\n",
              " ['order a new id card', 'new_id_card'],\n",
              " ['I need a new ID card', 'new_id_card'],\n",
              " ['order new id card', 'new_id_card'],\n",
              " ['get a new id card', 'new_id_card'],\n",
              " [\"i can't find my ID card\", 'new_id_card'],\n",
              " ['i lost id card', 'new_id_card'],\n",
              " ['what is the status of my claim?', 'claim_status'],\n",
              " ['claim status', 'claim_status'],\n",
              " ['has my claim been processed?', 'claim_status'],\n",
              " ['tell me about my claim', 'claim_status'],\n",
              " ['has my claim been paid?', 'claim_status'],\n",
              " ['was my claim paid?', 'claim_status'],\n",
              " ['what do i owe on my claim?', 'claim_status'],\n",
              " ['i want to check the status of my claim', 'claim_status'],\n",
              " ['what is the status of claim [X123456](claim_id)', 'claim_status'],\n",
              " ['has claim [YY4567890](claim_id) been paid?', 'claim_status'],\n",
              " ['check the status of claim [ZZ643421](claim_id)', 'claim_status'],\n",
              " ['check the status of a claim', 'claim_status'],\n",
              " ['I need to check my claim status', 'claim_status'],\n",
              " ['check claim status', 'claim_status'],\n",
              " ['view my claims', 'claim_status'],\n",
              " ['show my claims', 'claim_status'],\n",
              " ['view my recent claims', 'claim_status'],\n",
              " ['show me my claims', 'claim_status'],\n",
              " ['what is my claim history', 'claim_status'],\n",
              " ['get claim status', 'claim_status'],\n",
              " ['show some claims', 'claim_status'],\n",
              " ['check claim id 748536', 'claim_status'],\n",
              " ['check the status of claim [NC239062](claim_id)', 'claim_status'],\n",
              " ['has my claim been submitted?', 'claim_status'],\n",
              " ['what is the status of claim [XX123456](claim_id)[XX123456](claim_id)',\n",
              "  'claim_status'],\n",
              " ['check up on a claim', 'claim_status'],\n",
              " ['what is the status of claim [XX123456](claim_id)', 'claim_status'],\n",
              " ['what is the status of claim [NC709186](claim_id)[NC709186](claim_id)?',\n",
              "  'claim_status'],\n",
              " ['what is the status of my recent claim?', 'claim_status'],\n",
              " ['check the status of claim [NC339723](claim_id)[NC339723](claim_id)',\n",
              "  'claim_status'],\n",
              " ['check status of my claim', 'claim_status'],\n",
              " ['check on my claim status', 'claim_status'],\n",
              " ['file a claim', 'file_a_claim'],\n",
              " ['make a claim', 'file_a_claim'],\n",
              " ['i need to file a claim', 'file_a_claim'],\n",
              " ['submit a claim', 'file_a_claim'],\n",
              " ['submit a new claim', 'file_a_claim'],\n",
              " ['make a new claim', 'file_a_claim'],\n",
              " ['i crashed my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}',\n",
              "  'file_a_claim'],\n",
              " ['file new claim', 'file_a_claim'],\n",
              " ['file a [health](quote_insurance_type) insurance claim', 'file_a_claim'],\n",
              " ['file [health](quote_insurance_type) insurance claim', 'file_a_claim'],\n",
              " ['a tree fell on my [house](quote_insurance_type)', 'file_a_claim'],\n",
              " ['file a [life](quote_insurance_type) insurance claim', 'file_a_claim'],\n",
              " ['i had a procedure and need to file a claim', 'file_a_claim'],\n",
              " ['actually file a claim', 'file_a_claim'],\n",
              " ['i was in a [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} crash',\n",
              "  'file_a_claim'],\n",
              " ['file a new claim', 'file_a_claim'],\n",
              " ['pay a [claim](payment_type)', 'make_payment'],\n",
              " ['make a payment', 'make_payment'],\n",
              " ['pay off a [claim](payment_type)', 'make_payment'],\n",
              " ['pay what i owe', 'make_payment'],\n",
              " ['pay my bill', 'make_payment'],\n",
              " ['submit a payment', 'make_payment'],\n",
              " ['pay [claim](payment_type)', 'make_payment'],\n",
              " ['pay bill', 'make_payment'],\n",
              " ['i want to pay a [claim](payment_type)', 'make_payment'],\n",
              " ['make a [claim](payment_type) payment', 'make_payment'],\n",
              " ['payment', 'make_payment'],\n",
              " ['bill', 'make_payment'],\n",
              " [\"what's my bill\", 'make_payment'],\n",
              " ['do i owe a payment', 'make_payment'],\n",
              " ['pay my deductible', 'make_payment'],\n",
              " ['i need insurance', 'get_a_quote'],\n",
              " ['i need [health](quote_insurance_type) insurance', 'get_a_quote'],\n",
              " ['i need a quote', 'get_a_quote'],\n",
              " ['i need a quote for [car](quote_insurance_type) insurance', 'get_a_quote'],\n",
              " ['how much will [healthcare](quote_insurance_type) insurance cost?',\n",
              "  'get_a_quote'],\n",
              " ['can you give me a quote for [life](quote_insurance_type) insurance?',\n",
              "  'get_a_quote'],\n",
              " ['quote', 'get_a_quote'],\n",
              " ['insurance quote', 'get_a_quote'],\n",
              " ['can you give me a quote?', 'get_a_quote'],\n",
              " ['how much will coverage cost?', 'get_a_quote'],\n",
              " ['how much will insurance cost?', 'get_a_quote'],\n",
              " ['can i get an insurance quote?', 'get_a_quote'],\n",
              " ['i need an insurance quote', 'get_a_quote'],\n",
              " ['give me a [health](quote_insurance_type) insurance quote', 'get_a_quote'],\n",
              " ['get a quote', 'get_a_quote'],\n",
              " [\"i'm looking to purchase insurance\", 'get_a_quote'],\n",
              " [\"i'm in the market to get [life](quote_insurance_type) insurance\",\n",
              "  'get_a_quote'],\n",
              " ['get new insurance', 'get_a_quote'],\n",
              " ['i need [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"} insurance',\n",
              "  'get_a_quote'],\n",
              " ['i need to insure my [car]{\"entity\": \"quote_insurance_type\", \"value\": \"auto\"}',\n",
              "  'get_a_quote']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeEGLnP4AKR"
      },
      "source": [
        "# ***NLQ2SQL***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fabcIcko4Efn"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrIj-_V-4QzG",
        "outputId": "628d0df1-632d-4030-ff64-6a859cd43bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['question', 'sql']\n",
            "['What is the current series where the new series began in June 2011?', 'SELECT Current series FROM table WHERE Notes = New series began in June 2011']\n"
          ]
        }
      ],
      "source": [
        "rows = []\n",
        "with open(\"/content/train.csv\", 'r') as f:\n",
        "    csvreader = csv.reader(f)\n",
        "    header = next(csvreader)\n",
        "    for row in csvreader:\n",
        "        rows.append(row)\n",
        "print(header)\n",
        "print(rows[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuIrUU3k4wfe"
      },
      "outputs": [],
      "source": [
        "with open(\"datasql.txt\",'a') as f:\n",
        "  for i in rows:\n",
        "    f.write(\"[NQ] : \"+i[0]+\"\\n\")\n",
        "    f.write(\"[SQL] : \"+i[1]+\"\\n\")\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dK4YtEHC8tLW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "romctxKgFF2K"
      },
      "source": [
        "PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_8u2en3FGbC",
        "outputId": "00299eca-d000-4e51-91e6-99cf49a8c967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PDFminer\n",
            "  Downloading pdfminer-20191125.tar.gz (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 33.4 MB/s \n",
            "\u001b[?25hCollecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 4.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PDFminer\n",
            "  Building wheel for PDFminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PDFminer: filename=pdfminer-20191125-py3-none-any.whl size=6140086 sha256=6cf5a7fc7d27a179d2b2a4ca25124a09325bdaf5d5dbc33516b0f0e844dd850f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/5e/f4/d210b46e9e4a28229ea070ed5b3efa92c3c29d1a7918dd4b97\n",
            "Successfully built PDFminer\n",
            "Installing collected packages: pycryptodome, PDFminer\n",
            "Successfully installed PDFminer-20191125 pycryptodome-3.15.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install PDFminer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWDa8VzhFNmV"
      },
      "outputs": [],
      "source": [
        "from PDFminer.high_level import extract_text\n",
        "PDF_read = extract_text('document_path.PDF')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "56GAKlfBKujn",
        "Kdm-Q8GWOyAB",
        "078AdimpMTG9",
        "Wo2pcww4bSa-",
        "1p__5yLrAdoM",
        "h3ju1bMm2Uyh",
        "P0CqeqpclpN8",
        "2y7LrZzs7GVC",
        "mmeEGLnP4AKR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}